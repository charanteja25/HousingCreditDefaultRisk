{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed5e3800-a256-48a6-95ac-d5d482805a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install lightgbm\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18094e00-a735-436f-83f0-0fd7a813dcd4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports and Utilities"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Utilities\n",
    "# Purpose: Import essential libraries for Spark, LightGBM, sklearn, matplotlib, and seaborn.\n",
    "# Note: The one_hot_encode function is commented out and not used in the current pipeline. It was removed for simplicity and performance.\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as F\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "# def one_hot_encode(df, input_col, output_col_prefix):\n",
    "#     indexer = StringIndexer(inputCol=input_col, outputCol=f\"{input_col}_index\")\n",
    "#     encoder = OneHotEncoder(inputCol=f\"{input_col}_index\", outputCol=f\"{output_col_prefix}_vec\")\n",
    "#     pipeline = Pipeline(stages=[indexer, encoder])\n",
    "#     model = pipeline.fit(df)\n",
    "#     encoded_df = model.transform(df)\n",
    "#     return encoded_df\n",
    "\n",
    "# Example usage:\n",
    "# encoded_df = one_hot_encode(df, \"category_column\", \"category\")\n",
    "# display(encoded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e704068f-6eb3-47b9-a752-4b8eaea9e984",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Timer Context Manager"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2: Timer Context Manager\n",
    "# Purpose: Defines a timer context manager for profiling code execution, useful for measuring the runtime of pipeline steps.\n",
    "from contextlib import contextmanager\n",
    "import time\n",
    "import gc\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63f29eba-ed32-4eb1-afc5-489566d66f92",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Application Data Feature Engineering"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 3: Application Data Feature Engineering\n",
    "# Purpose: Loads training and test data from Spark tables, processes missing values, creates new features, and merges train/test sets for modeling.\n",
    "# Note: Spark one-hot encoding for binary features is commented out and not used. Numeric-only pipeline for simplicity and performance.\n",
    "def application_train_test(num_rows=None, nan_as_category=True):\n",
    "    df = spark.table(\"creditrisk_catalog.silver_creditrisk.app_train\")\n",
    "    test_df = spark.table(\"creditrisk_catalog.silver_creditrisk.app_test\")\n",
    "    if num_rows:\n",
    "        df = df.limit(num_rows)\n",
    "        test_df = test_df.limit(num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(df.count(), test_df.count()))\n",
    "    test_df = test_df.withColumn(\"TARGET\", F.lit(None))\n",
    "    df = df.unionByName(test_df)\n",
    "    # Remove Spark one-hot encoding\n",
    "    # for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "    #     df = one_hot_encode(df, bin_feature, bin_feature)\n",
    "    df = df.withColumn('DAYS_EMPLOYED', F.when(df['DAYS_EMPLOYED'] == 365243, None).otherwise(df['DAYS_EMPLOYED']))\n",
    "    df = df.withColumn('DAYS_EMPLOYED_PERC', F.try_divide(df['DAYS_EMPLOYED'], df['DAYS_BIRTH'])) \\\n",
    "           .withColumn('INCOME_CREDIT_PERC', F.try_divide(df['AMT_INCOME_TOTAL'], df['AMT_CREDIT'])) \\\n",
    "           .withColumn('INCOME_PER_PERSON', F.try_divide(df['AMT_INCOME_TOTAL'], df['CNT_FAM_MEMBERS'])) \\\n",
    "           .withColumn('ANNUITY_INCOME_PERC', F.try_divide(df['AMT_ANNUITY'], df['AMT_INCOME_TOTAL']))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f078938-f1f3-4846-a934-3611cfa1ad14",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Bureau and Bureau Balance Feature Engineering"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 4: Bureau and Bureau Balance Feature Engineering\n",
    "# Purpose: Aggregates bureau and bureau_balance tables, engineers features via groupBy and aggregation, and joins results for downstream use.\n",
    "# Note: Spark one-hot encoding and categorical feature aggregation are commented out and not used. Numeric-only pipeline for simplicity and performance.\n",
    "def bureau_and_balance(num_rows=None, nan_as_category=True):\n",
    "    bureau = spark.table(\"creditrisk_catalog.silver_creditrisk.bureau\")\n",
    "    bb = spark.table(\"creditrisk_catalog.silver_creditrisk.bureau_balance\")\n",
    "    if num_rows:\n",
    "        bureau = bureau.limit(num_rows)\n",
    "        bb = bb.limit(num_rows)\n",
    "    # Remove Spark one-hot encoding\n",
    "    # bb = one_hot_encode(bb, \"STATUS\", \"STATUS\")\n",
    "    # bureau = one_hot_encode(bureau, \"CREDIT_ACTIVE\", \"CREDIT_ACTIVE\")\n",
    "    bb_agg_exprs = [\n",
    "        F.min(\"MONTHS_BALANCE\").alias(\"MONTHS_BALANCE_MIN\"),\n",
    "        F.max(\"MONTHS_BALANCE\").alias(\"MONTHS_BALANCE_MAX\"),\n",
    "        F.count(\"MONTHS_BALANCE\").alias(\"MONTHS_BALANCE_SIZE\"),\n",
    "    ]\n",
    "    bb_agg = bb.groupBy(\"SK_ID_BUREAU\").agg(*bb_agg_exprs)\n",
    "    bureau = bureau.join(bb_agg, on=\"SK_ID_BUREAU\", how=\"left\")\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': [F.min, F.max, F.mean, F.variance],\n",
    "        'CREDIT_DAY_OVERDUE': [F.max, F.mean],\n",
    "        'DAYS_CREDIT_ENDDATE': [F.min, F.max, F.mean],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': [F.mean],\n",
    "        'CNT_CREDIT_PROLONG': [F.sum],\n",
    "        'AMT_CREDIT_SUM': [F.max, F.mean, F.sum],\n",
    "        'AMT_CREDIT_SUM_DEBT': [F.max, F.mean, F.sum],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': [F.mean],\n",
    "        'AMT_CREDIT_SUM_LIMIT': [F.mean, F.sum],\n",
    "        'DAYS_CREDIT_UPDATE': [F.min, F.max, F.mean],\n",
    "        'AMT_ANNUITY': [F.max, F.mean],\n",
    "        'MONTHS_BALANCE_MIN': [F.min],\n",
    "        'MONTHS_BALANCE_MAX': [F.max],\n",
    "        'MONTHS_BALANCE_SIZE': [F.mean, F.sum]\n",
    "    }\n",
    "    agg_exprs = []\n",
    "    for col, funcs in num_aggregations.items():\n",
    "        for func in funcs:\n",
    "            agg_exprs.append(func(col).alias(f\"BURO_{col}_{func.__name__.upper()}\"))\n",
    "    # Remove categorical feature aggregation\n",
    "    # cat_features = ['CREDIT_ACTIVE_vec', 'CREDIT_CURRENCY_vec', 'CREDIT_TYPE_vec']\n",
    "    # for cat in cat_features:\n",
    "    #     agg_exprs.append(F.mean(cat).alias(f\"BURO_{cat}_MEAN\"))\n",
    "    bureau_agg = bureau.groupBy(\"SK_ID_CURR\").agg(*agg_exprs)\n",
    "    # Remove active and closed credit aggregations that use CREDIT_ACTIVE_vec[1] and [2]\n",
    "    # active = bureau.filter(F.col('CREDIT_ACTIVE_vec')[1] == 1)\n",
    "    # active_agg = active.groupBy(\"SK_ID_CURR\").agg(*[\n",
    "    #     func(col).alias(f\"ACT_{col}_{func.__name__.upper()}\")\n",
    "    #     for col, funcs in num_aggregations.items() for func in funcs\n",
    "    # ])\n",
    "    # bureau_agg = bureau_agg.join(active_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    # closed = bureau.filter(F.col('CREDIT_ACTIVE_vec')[2] == 1)\n",
    "    # closed_agg = closed.groupBy(\"SK_ID_CURR\").agg(*[\n",
    "    #     func(col).alias(f\"CLS_{col}_{func.__name__.upper()}\")\n",
    "    #     for col, funcs in num_aggregations.items() for func in funcs\n",
    "    # ])\n",
    "    # bureau_agg = bureau_agg.join(closed_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    return bureau_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29ee2501-7998-4772-b6e3-59ae60c17e2a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Previous Applications Feature Engineering"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 5: Previous Applications Feature Engineering\n",
    "# Purpose: Processes previous loan applications, handles missing values, engineers features, and aggregates by customer ID.\n",
    "# Note: Spark one-hot encoding and categorical aggregations are commented out and not used. Numeric-only pipeline for simplicity and performance.\n",
    "def previous_applications(num_rows=None, nan_as_category=True):\n",
    "    prev = spark.table(\"creditrisk_catalog.silver_creditrisk.previous_application\")\n",
    "    if num_rows:\n",
    "        prev = prev.limit(num_rows)\n",
    "    # prev = one_hot_encode(prev, \"NAME_CONTRACT_STATUS\", \"NAME_CONTRACT_STATUS\")\n",
    "    #365243 is a place holder for missing values\n",
    "    prev = prev.withColumn('DAYS_FIRST_DRAWING', F.when(prev['DAYS_FIRST_DRAWING'] == 365243, None).otherwise(prev['DAYS_FIRST_DRAWING']))\n",
    "    prev = prev.withColumn('DAYS_FIRST_DUE', F.when(prev['DAYS_FIRST_DUE'] == 365243, None).otherwise(prev['DAYS_FIRST_DUE']))\n",
    "    prev = prev.withColumn('DAYS_LAST_DUE_1ST_VERSION', F.when(prev['DAYS_LAST_DUE_1ST_VERSION'] == 365243, None).otherwise(prev['DAYS_LAST_DUE_1ST_VERSION']))\n",
    "    prev = prev.withColumn('DAYS_LAST_DUE', F.when(prev['DAYS_LAST_DUE'] == 365243, None).otherwise(prev['DAYS_LAST_DUE']))\n",
    "    prev = prev.withColumn('DAYS_TERMINATION', F.when(prev['DAYS_TERMINATION'] == 365243, None).otherwise(prev['DAYS_TERMINATION']))\n",
    "    # Update division to use F.try_divide\n",
    "    prev = prev.withColumn('APP_CREDIT_PERC', F.try_divide(prev['AMT_APPLICATION'], prev['AMT_CREDIT']))\n",
    "\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': [F.min, F.max, F.mean],\n",
    "        'AMT_APPLICATION': [F.min, F.max, F.mean],\n",
    "        'AMT_CREDIT': [F.min, F.max, F.mean],\n",
    "        'APP_CREDIT_PERC': [F.min, F.max, F.mean, F.variance],\n",
    "        'AMT_DOWN_PAYMENT': [F.min, F.max, F.mean],\n",
    "        'AMT_GOODS_PRICE': [F.min, F.max, F.mean],\n",
    "        'HOUR_APPR_PROCESS_START': [F.min, F.max, F.mean],\n",
    "        'RATE_DOWN_PAYMENT': [F.min, F.max, F.mean],\n",
    "        'DAYS_DECISION': [F.min, F.max, F.mean],\n",
    "        'CNT_PAYMENT': [F.mean, F.sum],\n",
    "    }\n",
    "\n",
    "    agg_exprs = []\n",
    "    for col, funcs in num_aggregations.items():\n",
    "        for func in funcs:\n",
    "            agg_exprs.append(func(col).alias(f\"PREV_{col}_{func.__name__.upper()}\"))\n",
    "\n",
    "    # cat_features = [c for c in prev.columns if c.startswith(\"NAME_CONTRACT_STATUS_vec\")]\n",
    "    # for cat in cat_features:\n",
    "    #     agg_exprs.append(F.mean(cat).alias(f\"PREV_{cat}_MEAN\"))\n",
    "\n",
    "    prev_agg = prev.groupBy(\"SK_ID_CURR\").agg(*agg_exprs)\n",
    "\n",
    "    # approved = prev.filter(F.col('NAME_CONTRACT_STATUS_vec')[1] == 1)\n",
    "    # approved_agg = approved.groupBy(\"SK_ID_CURR\").agg(*[\n",
    "    #     func(col).alias(f\"APR_{col}_{func.__name__.upper()}\")\n",
    "    #     for col, funcs in num_aggregations.items() for func in funcs\n",
    "    # ])\n",
    "    # prev_agg = prev_agg.join(approved_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "    # refused = prev.filter(F.col('NAME_CONTRACT_STATUS_vec')[2] == 1)\n",
    "    # refused_agg = refused.groupBy(\"SK_ID_CURR\").agg(*[\n",
    "    #     func(col).alias(f\"REF_{col}_{func.__name__.upper()}\")\n",
    "    #     for col, funcs in num_aggregations.items() for func in funcs\n",
    "    # ])\n",
    "    # prev_agg = prev_agg.join(refused_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "    return prev_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d910fa6-098c-41fe-9173-bd6b4010df44",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "POS Cash Balance Feature Engineering"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 6: POS Cash Balance Feature Engineering\n",
    "# Purpose: Processes POS cash balance data, aggregates time and delinquency features, and prepares them for joining.\n",
    "# Note: Spark one-hot encoding and categorical aggregations are commented out and not used. Numeric-only pipeline for simplicity and performance.\n",
    "def pos_cash(num_rows=None, nan_as_category=True):\n",
    "    pos = spark.table(\"creditrisk_catalog.silver_creditrisk.pos_cash_balance\")\n",
    "    if num_rows:\n",
    "        pos = pos.limit(num_rows)\n",
    "    # pos = one_hot_encode(pos, \"NAME_CONTRACT_STATUS\", \"NAME_CONTRACT_STATUS\")\n",
    "    agg_exprs = [\n",
    "        F.max(\"MONTHS_BALANCE\").alias(\"POS_MONTHS_BALANCE_MAX\"),\n",
    "        F.mean(\"MONTHS_BALANCE\").alias(\"POS_MONTHS_BALANCE_MEAN\"),\n",
    "        F.count(\"MONTHS_BALANCE\").alias(\"POS_MONTHS_BALANCE_SIZE\"),\n",
    "        F.max(\"SK_DPD\").alias(\"POS_SK_DPD_MAX\"),\n",
    "        F.mean(\"SK_DPD\").alias(\"POS_SK_DPD_MEAN\"),\n",
    "        F.max(\"SK_DPD_DEF\").alias(\"POS_SK_DPD_DEF_MAX\"),\n",
    "        F.mean(\"SK_DPD_DEF\").alias(\"POS_SK_DPD_DEF_MEAN\"),\n",
    "    ]\n",
    "    # cat_features = [c for c in pos.columns if c.startswith(\"NAME_CONTRACT_STATUS_vec\")]\n",
    "    # for cat in cat_features:\n",
    "    #     agg_exprs.append(F.mean(cat).alias(f\"POS_{cat}_MEAN\"))\n",
    "    pos_agg = pos.groupBy(\"SK_ID_CURR\").agg(*agg_exprs)\n",
    "    pos_agg = pos_agg.withColumn(\"POS_COUNT\", F.lit(None))\n",
    "    return pos_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aede06b-e5d9-46a1-9f4a-4ac4d039a6cc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Bureau Balance (Alternate Version)"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 7: Bureau Balance (Alternate Version)\n",
    "# Purpose: Alternate version of bureau_and_balance, similar to Cell 4, with minor code differences in categorical feature handling and aggregation.\n",
    "# Note: Spark one-hot encoding and categorical feature aggregation are commented out and not used. Numeric-only pipeline for simplicity and performance.\n",
    "def bureau_and_balance(num_rows=None, nan_as_category=True):\n",
    "    bureau = spark.table(\"creditrisk_catalog.silver_creditrisk.bureau\")\n",
    "    bb = spark.table(\"creditrisk_catalog.silver_creditrisk.bureau_balance\")\n",
    "    if num_rows:\n",
    "        bureau = bureau.limit(num_rows)\n",
    "        bb = bb.limit(num_rows)\n",
    "    # bb = one_hot_encode(bb, \"STATUS\", \"STATUS\")\n",
    "    # bureau = one_hot_encode(bureau, \"CREDIT_ACTIVE\", \"CREDIT_ACTIVE\")\n",
    "    bb_agg_exprs = [\n",
    "        F.min(\"MONTHS_BALANCE\").alias(\"MONTHS_BALANCE_MIN\"),\n",
    "        F.max(\"MONTHS_BALANCE\").alias(\"MONTHS_BALANCE_MAX\"),\n",
    "        F.count(\"MONTHS_BALANCE\").alias(\"MONTHS_BALANCE_SIZE\"),\n",
    "    ]\n",
    "    bb_agg = bb.groupBy(\"SK_ID_BUREAU\").agg(*bb_agg_exprs)\n",
    "    bureau = bureau.join(bb_agg, on=\"SK_ID_BUREAU\", how=\"left\")\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': [F.min, F.max, F.mean, F.variance],\n",
    "        'CREDIT_DAY_OVERDUE': [F.max, F.mean],\n",
    "        'DAYS_CREDIT_ENDDATE': [F.min, F.max, F.mean],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': [F.mean],\n",
    "        'CNT_CREDIT_PROLONG': [F.sum],\n",
    "        'AMT_CREDIT_SUM': [F.max, F.mean, F.sum],\n",
    "        'AMT_CREDIT_SUM_DEBT': [F.max, F.mean, F.sum],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': [F.mean],\n",
    "        'AMT_CREDIT_SUM_LIMIT': [F.mean, F.sum],\n",
    "        'DAYS_CREDIT_UPDATE': [F.min, F.max, F.mean],\n",
    "        'AMT_ANNUITY': [F.max, F.mean],\n",
    "        'MONTHS_BALANCE_MIN': [F.min],\n",
    "        'MONTHS_BALANCE_MAX': [F.max],\n",
    "        'MONTHS_BALANCE_SIZE': [F.mean, F.sum]\n",
    "    }\n",
    "    agg_exprs = []\n",
    "    for col, funcs in num_aggregations.items():\n",
    "        for func in funcs:\n",
    "            agg_exprs.append(func(col).alias(f\"BURO_{col}_{func.__name__.upper()}\"))\n",
    "    # bureau_cat_features = [c for c in bureau.columns if c.startswith(\"CREDIT_ACTIVE_vec\")]\n",
    "    # for cat in bureau_cat_features:\n",
    "    #     agg_exprs.append(F.mean(cat).alias(f\"BURO_{cat}_MEAN\"))\n",
    "    bureau_agg = bureau.groupBy(\"SK_ID_CURR\").agg(*agg_exprs)\n",
    "    # Minimal fix: Remove active and closed credit aggregations that use CREDIT_ACTIVE_vec[1] and [2]\n",
    "    # active = bureau.filter(F.col(\"CREDIT_ACTIVE_vec\")[1] == 1)\n",
    "    # active_agg_exprs = []\n",
    "    # for col, funcs in num_aggregations.items():\n",
    "    #     for func in funcs:\n",
    "    #         active_agg_exprs.append(func(col).alias(f\"ACT_{col}_{func.__name__.upper()}\"))\n",
    "    # active_agg = active.groupBy(\"SK_ID_CURR\").agg(*active_agg_exprs)\n",
    "    # bureau_agg = bureau_agg.join(active_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    # closed = bureau.filter(F.col(\"CREDIT_ACTIVE_vec\")[2] == 1)\n",
    "    # closed_agg_exprs = []\n",
    "    # for col, funcs in num_aggregations.items():\n",
    "    #     for func in funcs:\n",
    "    #         closed_agg_exprs.append(func(col).alias(f\"CLS_{col}_{func.__name__.upper()}\"))\n",
    "    # closed_agg = closed.groupBy(\"SK_ID_CURR\").agg(*closed_agg_exprs)\n",
    "    # bureau_agg = bureau_agg.join(closed_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    return bureau_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdd33982-101a-48d6-bc8a-3f0a245aa5e9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Installments Payments Feature Engineering"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 8: Installments Payments Feature Engineering\n",
    "# Purpose: Processes installment payment data, engineers payment and delinquency features, and aggregates by customer ID.\n",
    "# Note: Spark one-hot encoding and categorical aggregations are commented out and not used. Numeric-only pipeline for simplicity and performance.\n",
    "def installments_payments(num_rows=None, nan_as_category=True):\n",
    "    ins = spark.table(\"creditrisk_catalog.silver_creditrisk.installments_payments\")\n",
    "    if num_rows:\n",
    "        ins = ins.limit(num_rows)\n",
    "    # Remove Spark one-hot encoding\n",
    "    # ins = one_hot_encode(ins, \"NAME_CONTRACT_TYPE\", \"NAME_CONTRACT_TYPE\")\n",
    "    ins = ins.withColumn(\"PAYMENT_PERC\", F.try_divide(F.col(\"AMT_PAYMENT\"), F.col(\"AMT_INSTALMENT\")))\n",
    "    ins = ins.withColumn(\"PAYMENT_DIFF\", F.col(\"AMT_INSTALMENT\") - F.col(\"AMT_PAYMENT\"))\n",
    "    ins = ins.withColumn(\"DPD\", F.when(F.col(\"DAYS_ENTRY_PAYMENT\") - F.col(\"DAYS_INSTALMENT\") > 0, F.col(\"DAYS_ENTRY_PAYMENT\") - F.col(\"DAYS_INSTALMENT\")).otherwise(0))\n",
    "    ins = ins.withColumn(\"DBD\", F.when(F.col(\"DAYS_INSTALMENT\") - F.col(\"DAYS_ENTRY_PAYMENT\") > 0, F.col(\"DAYS_INSTALMENT\") - F.col(\"DAYS_ENTRY_PAYMENT\")).otherwise(0))\n",
    "    agg_exprs = [\n",
    "        F.countDistinct(\"NUM_INSTALMENT_VERSION\").alias(\"INS_NUM_INSTALMENT_VERSION_NUNIQUE\"),\n",
    "        F.max(\"DPD\").alias(\"INS_DPD_MAX\"),\n",
    "        F.mean(\"DPD\").alias(\"INS_DPD_MEAN\"),\n",
    "        F.sum(\"DPD\").alias(\"INS_DPD_SUM\"),\n",
    "        F.max(\"DBD\").alias(\"INS_DBD_MAX\"),\n",
    "        F.mean(\"DBD\").alias(\"INS_DBD_MEAN\"),\n",
    "        F.sum(\"DBD\").alias(\"INS_DBD_SUM\"),\n",
    "        F.max(\"PAYMENT_PERC\").alias(\"INS_PAYMENT_PERC_MAX\"),\n",
    "        F.mean(\"PAYMENT_PERC\").alias(\"INS_PAYMENT_PERC_MEAN\"),\n",
    "        F.sum(\"PAYMENT_PERC\").alias(\"INS_PAYMENT_PERC_SUM\"),\n",
    "        F.variance(\"PAYMENT_PERC\").alias(\"INS_PAYMENT_PERC_VAR\"),\n",
    "        F.max(\"PAYMENT_DIFF\").alias(\"INS_PAYMENT_DIFF_MAX\"),\n",
    "        F.mean(\"PAYMENT_DIFF\").alias(\"INS_PAYMENT_DIFF_MEAN\"),\n",
    "        F.sum(\"PAYMENT_DIFF\").alias(\"INS_PAYMENT_DIFF_SUM\"),\n",
    "        F.variance(\"PAYMENT_DIFF\").alias(\"INS_PAYMENT_DIFF_VAR\"),\n",
    "        F.max(\"AMT_INSTALMENT\").alias(\"INS_AMT_INSTALMENT_MAX\"),\n",
    "        F.mean(\"AMT_INSTALMENT\").alias(\"INS_AMT_INSTALMENT_MEAN\"),\n",
    "        F.sum(\"AMT_INSTALMENT\").alias(\"INS_AMT_INSTALMENT_SUM\"),\n",
    "        F.min(\"AMT_PAYMENT\").alias(\"INS_AMT_PAYMENT_MIN\"),\n",
    "        F.max(\"AMT_PAYMENT\").alias(\"INS_AMT_PAYMENT_MAX\"),\n",
    "        F.mean(\"AMT_PAYMENT\").alias(\"INS_AMT_PAYMENT_MEAN\"),\n",
    "        F.sum(\"AMT_PAYMENT\").alias(\"INS_AMT_PAYMENT_SUM\"),\n",
    "        F.max(\"DAYS_ENTRY_PAYMENT\").alias(\"INS_DAYS_ENTRY_PAYMENT_MAX\"),\n",
    "        F.mean(\"DAYS_ENTRY_PAYMENT\").alias(\"INS_DAYS_ENTRY_PAYMENT_MEAN\"),\n",
    "        F.sum(\"DAYS_ENTRY_PAYMENT\").alias(\"INS_DAYS_ENTRY_PAYMENT_SUM\"),\n",
    "    ]\n",
    "    # Remove categorical feature aggregation\n",
    "    # cat_features = [c for c in ins.columns if c.startswith(\"NAME_CONTRACT_TYPE_vec\")]\n",
    "    # for cat in cat_features:\n",
    "    #     agg_exprs.append(F.mean(cat).alias(f\"INS_{cat}_MEAN\"))\n",
    "    ins_agg = ins.groupBy(\"SK_ID_CURR\").agg(*agg_exprs)\n",
    "    ins_agg = ins_agg.withColumn(\"INS_COUNT\", F.lit(None))\n",
    "    return ins_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69006b85-b57e-4347-a260-43d88644adbb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "credit_card_balance"
    }
   },
   "outputs": [],
   "source": [
    "def credit_card_balance(num_rows=None, nan_as_category=True):\n",
    "    cc = spark.table(\"creditrisk_catalog.silver_creditrisk.credit_card_balance\")\n",
    "    if num_rows:\n",
    "        cc = cc.limit(num_rows)\n",
    "    # Remove Spark one-hot encoding\n",
    "    # cc = one_hot_encode(cc, \"NAME_CONTRACT_STATUS\", \"NAME_CONTRACT_STATUS\")\n",
    "    cc = cc.drop(\"SK_ID_PREV\")\n",
    "    # Only aggregate numeric columns\n",
    "    num_cols = [c for c, t in cc.dtypes if c != \"SK_ID_CURR\" and t in [\"int\", \"bigint\", \"double\", \"float\", \"decimal\"]]\n",
    "    agg_exprs = []\n",
    "    for col in num_cols:\n",
    "        agg_exprs.extend([\n",
    "            F.min(col).alias(f\"CC_{col}_MIN\"),\n",
    "            F.max(col).alias(f\"CC_{col}_MAX\"),\n",
    "            F.mean(col).alias(f\"CC_{col}_MEAN\"),\n",
    "            F.sum(col).alias(f\"CC_{col}_SUM\"),\n",
    "            F.variance(col).alias(f\"CC_{col}_VAR\")\n",
    "        ])\n",
    "    cc_agg = cc.groupBy(\"SK_ID_CURR\").agg(*agg_exprs)\n",
    "    cc_count = cc.groupBy(\"SK_ID_CURR\").count().withColumnRenamed(\"count\", \"CC_COUNT\")\n",
    "    cc_agg = cc_agg.join(cc_count, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    return cc_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "482e20b1-29a9-4b97-a5ba-9d4e4fbba808",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "LightGBM Modeling with PySpark and MLflow Integration (signature only, no input_example)"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 10: LightGBM Modeling with PySpark and MLflow Integration (signature only, no input_example)\n",
    "# Purpose: Trains LightGBM model with KFold cross-validation, logs parameters, metrics, and model artifacts to MLflow for experiment tracking and reproducibility.\n",
    "# MLflow integration added for tracking and model management. Additional metrics (accuracy, precision, recall, F1, log loss) are logged for each fold and overall.\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "def kfold_lightgbm_pyspark(df, num_folds, stratified=True, explain=False, submission_file_name='submission.csv'):\n",
    "    \"\"\"\n",
    "    LightGBM GBDT with KFold or Stratified KFold using PySpark DataFrames\n",
    "    Optimized for serverless compute (no caching/persistence)\n",
    "    Logs parameters, metrics, and model artifacts to MLflow.\n",
    "    \"\"\"\n",
    "    import gc\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import KFold, StratifiedKFold\n",
    "    from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, log_loss, roc_curve, confusion_matrix, precision_recall_curve\n",
    "    import lightgbm as lgb\n",
    "    from pyspark.sql import functions as F\n",
    "    from pyspark.sql.window import Window\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Split train and test using PySpark\n",
    "    train_df = df.filter(F.col('TARGET').isNotNull())\n",
    "    test_df = df.filter(F.col('TARGET').isNull())\n",
    "\n",
    "    train_count = train_df.count()\n",
    "    test_count = test_df.count()\n",
    "    print(f\"Starting LightGBM. Train count: {train_count}, test count: {test_count}\")\n",
    "\n",
    "    # Add fold assignment in PySpark for stratified sampling\n",
    "    if stratified:\n",
    "        window_spec = Window.partitionBy('TARGET').orderBy(F.rand(seed=1001))\n",
    "        train_df = train_df.withColumn('row_num', F.row_number().over(window_spec))\n",
    "        train_df = train_df.withColumn('fold', (F.col('row_num') % num_folds).cast('int'))\n",
    "    else:\n",
    "        train_df = train_df.withColumn('rand', F.rand(seed=1001))\n",
    "        train_df = train_df.withColumn('fold', (F.ntile(num_folds).over(Window.orderBy('rand')) - 1).cast('int'))\n",
    "\n",
    "    train_pd = train_df.toPandas()\n",
    "    test_pd = test_df.toPandas()\n",
    "\n",
    "    for col in train_pd.select_dtypes(include=['object']).columns:\n",
    "        if col not in ['fold']:\n",
    "            train_pd[col] = train_pd[col].astype('category')\n",
    "    for col in test_pd.select_dtypes(include=['object']).columns:\n",
    "        test_pd[col] = test_pd[col].astype('category')\n",
    "\n",
    "    del train_df, test_df, df\n",
    "    gc.collect()\n",
    "\n",
    "    oof_preds = np.zeros(train_pd.shape[0])\n",
    "    sub_preds = np.zeros(test_pd.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_pd.columns if f not in ['TARGET', 'SK_ID_CURR', 'SK_ID_BUREAU', 'SK_ID_PREV', 'fold', 'row_num', 'rand']]\n",
    "\n",
    "    params = {\n",
    "        'nthread': 4,\n",
    "        'n_estimators': 10000,\n",
    "        'learning_rate': 0.02,\n",
    "        'num_leaves': 34,\n",
    "        'colsample_bytree': 0.9497036,\n",
    "        'subsample': 0.8715623,\n",
    "        'max_depth': 8,\n",
    "        'reg_alpha': 0.041545473,\n",
    "        'reg_lambda': 0.0735294,\n",
    "        'min_split_gain': 0.0222415,\n",
    "        'min_child_weight': 39.3259775,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    # Start MLflow run for experiment tracking\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"num_folds\", num_folds)\n",
    "        mlflow.log_param(\"stratified\", stratified)\n",
    "        for k, v in params.items():\n",
    "            mlflow.log_param(k, v)\n",
    "\n",
    "        model = None  # Minimal fix: ensure model is defined outside the loop\n",
    "        for fold_num in range(num_folds):\n",
    "            print(f'\\n--- Fold {fold_num + 1} / {num_folds} ---')\n",
    "            train_idx = train_pd['fold'] != fold_num\n",
    "            valid_idx = train_pd['fold'] == fold_num\n",
    "            train_x = train_pd.loc[train_idx, feats]\n",
    "            train_y = train_pd.loc[train_idx, 'TARGET']\n",
    "            valid_x = train_pd.loc[valid_idx, feats]\n",
    "            valid_y = train_pd.loc[valid_idx, 'TARGET']\n",
    "            model = lgb.LGBMClassifier(**params)\n",
    "            model.fit(\n",
    "                train_x, train_y,\n",
    "                eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                eval_metric='auc',\n",
    "                callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    "            )\n",
    "            oof_preds[valid_idx] = model.predict_proba(valid_x, num_iteration=model.best_iteration_)[:, 1]\n",
    "            sub_preds += model.predict_proba(test_pd[feats], num_iteration=model.best_iteration_)[:, 1] / num_folds\n",
    "            fold_importance_df = pd.DataFrame({\n",
    "                'feature': feats,\n",
    "                'importance': model.feature_importances_,\n",
    "                'fold': fold_num + 1\n",
    "            })\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "            fold_auc = roc_auc_score(valid_y, oof_preds[valid_idx])\n",
    "            preds_binary = (oof_preds[valid_idx] > 0.5).astype(int)\n",
    "            fold_acc = accuracy_score(valid_y, preds_binary)\n",
    "            fold_prec = precision_score(valid_y, preds_binary)\n",
    "            fold_rec = recall_score(valid_y, preds_binary)\n",
    "            fold_f1 = f1_score(valid_y, preds_binary)\n",
    "            fold_logloss = log_loss(valid_y, oof_preds[valid_idx])\n",
    "            print(f'Fold {fold_num + 1} AUC : {fold_auc:.6f}, Accuracy: {fold_acc:.4f}, Precision: {fold_prec:.4f}, Recall: {fold_rec:.4f}, F1: {fold_f1:.4f}, LogLoss: {fold_logloss:.4f}')\n",
    "            mlflow.log_metric(f\"fold_{fold_num+1}_auc\", fold_auc)\n",
    "            mlflow.log_metric(f\"fold_{fold_num+1}_accuracy\", fold_acc)\n",
    "            mlflow.log_metric(f\"fold_{fold_num+1}_precision\", fold_prec)\n",
    "            mlflow.log_metric(f\"fold_{fold_num+1}_recall\", fold_rec)\n",
    "            mlflow.log_metric(f\"fold_{fold_num+1}_f1\", fold_f1)\n",
    "            mlflow.log_metric(f\"fold_{fold_num+1}_logloss\", fold_logloss)\n",
    "            if explain:\n",
    "                import shap\n",
    "                explainer = shap.TreeExplainer(model)\n",
    "                shap_values = explainer.shap_values(valid_x)\n",
    "                shap.summary_plot(shap_values, valid_x, feature_names=feats, show=False)\n",
    "            del train_x, train_y, valid_x, valid_y\n",
    "            gc.collect()\n",
    "        overall_auc = roc_auc_score(train_pd['TARGET'], oof_preds)\n",
    "        overall_preds_binary = (oof_preds > 0.5).astype(int)\n",
    "        overall_acc = accuracy_score(train_pd['TARGET'], overall_preds_binary)\n",
    "        overall_prec = precision_score(train_pd['TARGET'], overall_preds_binary)\n",
    "        overall_rec = recall_score(train_pd['TARGET'], overall_preds_binary)\n",
    "        overall_f1 = f1_score(train_pd['TARGET'], overall_preds_binary)\n",
    "        overall_logloss = log_loss(train_pd['TARGET'], oof_preds)\n",
    "        print(f'\\nFull AUC score: {overall_auc:.6f}, Accuracy: {overall_acc:.4f}, Precision: {overall_prec:.4f}, Recall: {overall_rec:.4f},            F1: {overall_f1:.4f}, LogLoss: {overall_logloss:.4f}')\n",
    "        mlflow.log_metric(\"overall_auc\", overall_auc)\n",
    "        mlflow.log_metric(\"overall_accuracy\", overall_acc)\n",
    "        mlflow.log_metric(\"overall_precision\", overall_prec)\n",
    "        mlflow.log_metric(\"overall_recall\", overall_rec)\n",
    "        mlflow.log_metric(\"overall_f1\", overall_f1)\n",
    "        mlflow.log_metric(\"overall_logloss\", overall_logloss)\n",
    "        submission_df = test_pd[['SK_ID_CURR']].copy()\n",
    "        submission_df['TARGET'] = sub_preds\n",
    "        submission_df.to_csv(submission_file_name, index=False)\n",
    "        print(f'Submission saved to {submission_file_name}')\n",
    "        mlflow.log_artifact(submission_file_name)\n",
    "        # Log the last trained model (minimal fix for UnboundLocalError)\n",
    "        input_example = train_pd[feats].head(5)\n",
    "        output_example = model.predict_proba(input_example)\n",
    "        signature = infer_signature(input_example, output_example)\n",
    "        mlflow.lightgbm.log_model(model, \"model\", signature=signature)\n",
    "        # Log ROC curve\n",
    "        fpr, tpr, _ = roc_curve(train_pd['TARGET'], oof_preds)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label='ROC Curve')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend()\n",
    "        mlflow.log_figure(plt.gcf(), \"roc_curve.png\")\n",
    "        plt.close()\n",
    "        # Log confusion matrix\n",
    "        cm = confusion_matrix(train_pd['TARGET'], overall_preds_binary)\n",
    "        plt.figure()\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        mlflow.log_figure(plt.gcf(), \"confusion_matrix.png\")\n",
    "        plt.close()\n",
    "        # Log Precision-Recall curve\n",
    "        precision, recall, _ = precision_recall_curve(train_pd['TARGET'], oof_preds)\n",
    "        plt.figure()\n",
    "        plt.plot(recall, precision, label='Precision-Recall Curve')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.legend()\n",
    "        mlflow.log_figure(plt.gcf(), \"precision_recall_curve.png\")\n",
    "        plt.close()\n",
    "        # Log histogram of predicted probabilities\n",
    "        plt.figure()\n",
    "        plt.hist(oof_preds, bins=50, color='skyblue', edgecolor='black')\n",
    "        plt.title('Histogram of Predicted Probabilities')\n",
    "        plt.xlabel('Predicted Probability')\n",
    "        plt.ylabel('Frequency')\n",
    "        mlflow.log_figure(plt.gcf(), \"predicted_prob_histogram.png\")\n",
    "        plt.close()\n",
    "        display_importances(feature_importance_df)\n",
    "    return feature_importance_df\n",
    "\n",
    "def display_importances(feature_importance_df):\n",
    "    \"\"\"\n",
    "    Display and plot feature importances\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    cols = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "        by=\"importance\", ascending=False\n",
    "    )[:40].index\n",
    "    best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(\n",
    "        x=\"importance\",\n",
    "        y=\"feature\",\n",
    "        data=best_features.sort_values(by=\"importance\", ascending=False),\n",
    "        palette=\"viridis\"\n",
    "    )\n",
    "    plt.title('LightGBM Feature Importance (Top 40)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances.png')\n",
    "    plt.show()\n",
    "    # Log feature importance plot to MLflow\n",
    "    mlflow.log_artifact('lgbm_importances.png')\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "eae20118-409c-4014-a129-7143f1024f38",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Legacy LightGBM Model (Commented Out for Reference)"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: The kfold_lightgbm function below is NOT used in the main pipeline.\n",
    "# Reason: Superseded by kfold_lightgbm_pyspark (cell 10), which is optimized for PySpark and serverless compute.\n",
    "# This function is kept for reference only and is commented out to avoid confusion.\n",
    "# If you need a Pandas-based implementation, you may refer to this code.\n",
    "\n",
    "# def kfold_lightgbm(df, num_folds, stratified=True, explain=False):\n",
    "#     import gc\n",
    "#     import numpy as np\n",
    "#     import pandas as pd\n",
    "#     from sklearn.model_selection import KFold, StratifiedKFold\n",
    "#     from sklearn.metrics import roc_auc_score\n",
    "#     import lightgbm as lgb\n",
    "#\n",
    "#     train_df = df.filter(F.col('TARGET').isNotNull())\n",
    "#     test_df = df.filter(F.col('TARGET').isNull())\n",
    "#     print(\"Starting LightGBM. Train count: {}, test count: {}\".format(train_df.count(), test_df.count()))\n",
    "#     train_pd = train_df.toPandas()\n",
    "#     test_pd = test_df.toPandas()\n",
    "#     # Minimal fix: convert object columns to category dtype\n",
    "#     for col in train_pd.select_dtypes(include=['object']).columns:\n",
    "#         train_pd[col] = train_pd[col].astype('category')\n",
    "#     for col in test_pd.select_dtypes(include=['object']).columns:\n",
    "#         test_pd[col] = test_pd[col].astype('category')\n",
    "#     del train_df, test_df, df\n",
    "#     gc.collect()\n",
    "#\n",
    "#     if stratified:\n",
    "#         folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "#     else:\n",
    "#         folds = KFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "#\n",
    "#     oof_preds = np.zeros(train_pd.shape[0])\n",
    "#     sub_preds = np.zeros(test_pd.shape[0])\n",
    "#     feature_importance_df = pd.DataFrame()\n",
    "#     feats = [f for f in train_pd.columns if f not in ['TARGET', 'SK_ID_CURR', 'SK_ID_BUREAU', 'SK_ID_PREV']]\n",
    "#\n",
    "#     params = {\n",
    "#         'nthread': 4,\n",
    "#         'n_estimators': 10000,\n",
    "#         'learning_rate': 0.02,\n",
    "#         'num_leaves': 34,\n",
    "#         'colsample_bytree': 0.9497036,\n",
    "#         'subsample': 0.8715623,\n",
    "#         'max_depth': 8,\n",
    "#         'reg_alpha': 0.041545473,\n",
    "#         'reg_lambda': 0.0735294,\n",
    "#         'min_split_gain': 0.0222415,\n",
    "#         'min_child_weight': 39.3259775,\n",
    "#         'silent': -1\n",
    "#     }\n",
    "#\n",
    "#     for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_pd[feats], train_pd['TARGET'])):\n",
    "#         train_x, train_y = train_pd[feats].iloc[train_idx], train_pd['TARGET'].iloc[train_idx]\n",
    "#         valid_x, valid_y = train_pd[feats].iloc[valid_idx], train_pd['TARGET'].iloc[valid_idx]\n",
    "#\n",
    "#         model = lgb.LGBMClassifier(**params)\n",
    "#         model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "#                   eval_metric='auc',  callbacks=[lgb.early_stopping(100)]\n",
    "#         )\n",
    "#\n",
    "#         oof_preds[valid_idx] = model.predict_proba(valid_x, num_iteration=model.best_iteration_)[:, 1]\n",
    "#         sub_preds += model.predict_proba(test_pd[feats], num_iteration=model.best_iteration_)[:, 1] / folds.n_splits\n",
    "#\n",
    "#         fold_importance_df = pd.DataFrame()\n",
    "#         fold_importance_df[\"feature\"] = feats\n",
    "#         fold_importance_df[\"importance\"] = model.feature_importances_\n",
    "#         fold_importance_df[\"fold\"] = n_fold + 1\n",
    "#         feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "#         print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "#\n",
    "#         if explain:\n",
    "#             import shap\n",
    "#             explainer = shap.TreeExplainer(model)\n",
    "#             shap_values = explainer.shap_values(valid_x)\n",
    "#             shap.summary_plot(shap_values, valid_x, feature_names=feats, show=False)\n",
    "#\n",
    "#         del model\n",
    "#         del train_x, train_y, valid_x, valid_y\n",
    "#         gc.collect()\n",
    "#\n",
    "#     print('Full AUC score %.6f' % roc_auc_score(train_pd['TARGET'], oof_preds))\n",
    "#     test_pd['TARGET'] = sub_preds\n",
    "#     test_pd[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index=False)\n",
    "#     display_importances(feature_importance_df)\n",
    "#     return feature_importance_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6815b1b8-fe3b-4c1a-b113-68dc66fad164",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def display_importances(feature_importance_df_):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances-01.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c18af16-cc03-40b2-87eb-1251d0b2b15e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def main(debug = False):\n",
    "    num_rows = 100000 if debug else None\n",
    "    df = application_train_test(num_rows)\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"Bureau df count:\", bureau.count())\n",
    "        df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "    with timer(\"Process previous_applications\"):\n",
    "        prev = previous_applications(num_rows)\n",
    "        print(\"Previous applications df count:\", prev.count())\n",
    "        df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "        del prev\n",
    "        gc.collect()\n",
    "    with timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"Pos-cash balance df count:\", pos.count())\n",
    "        df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "        del pos\n",
    "        gc.collect()\n",
    "    with timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"Installments payments df count:\", ins.count())\n",
    "        df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "        del ins\n",
    "        gc.collect()\n",
    "    with timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"Credit card balance df count:\", cc.count())\n",
    "        df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "        del cc\n",
    "        gc.collect()\n",
    "    with timer(\"Run LightGBM with kfold\"):\n",
    "        feature_importance = kfold_lightgbm_pyspark(\n",
    "            df=df,\n",
    "            num_folds=5,\n",
    "            stratified=True,\n",
    "            explain=False,\n",
    "            submission_file_name='submission.csv'\n",
    "        )\n",
    "if __name__ == \"__main__\":\n",
    "    submission_file_name = \"submission_kernel26.csv\"\n",
    "    with timer(\"Full model run\"):\n",
    "        main(debug= False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ML_CreditRisk_Evals",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
